# üîç Vulnerability Extractor

Uma ferramenta CLI para extrair vulnerabilidades de relat√≥rios PDF de seguran√ßa usando LLMs (Large Language Models).

## üìã Descri√ß√£o

Ferramenta para automatizar a extra√ß√£o, estrutura√ß√£o e convers√£o de vulnerabilidades de relat√≥rios PDF dos scanners OpenVAS e Tenable WAS, utilizando PLN e LLMs como GPT-4.1. Permite criar datasets padronizados para gest√£o de riscos e aplica√ß√µes em aprendizado de m√°quina.

## ‚ú® Funcionalidades

- Extra√ß√£o autom√°tica de vulnerabilidades de PDFs
- Remo√ß√£o de duplicatas baseada no nome da vulnerabilidade
- Suporte a m√∫ltiplos provedores de LLM (OpenAI, Groq, etc.)
- Configura√ß√£o via arquivo JSON
- Interface de linha de comando (CLI)
- Processamento em chunks para documentos grandes
- Convers√£o para CSV/XLSX/TSV
- Tratamento robusto de erros

## üöÄ Instala√ß√£o

1. Clone ou baixe os arquivos
```bash
git clone <reposit√≥rio>
cd pdf-vulnerability-extractor
```

2. Crie um ambiente virtual (recomendado)
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# ou
source venv/bin/activate  # Linux/Mac
```

3. Instale as depend√™ncias
```bash
pip install -r requirements.txt
```

### Depend√™ncias principais
- `langchain` - Framework principal para LLM
- `langchain-openai` - Interface para APIs OpenAI/Groq
- `langchain-community` - Loaders e utilit√°rios
- `unstructured[pdf]` - Processamento de PDFs
- `PyPDF2`, `pdfplumber` - Extra√ß√£o de texto
- `pandas` - Manipula√ß√£o de dados

## ‚öôÔ∏è Configura√ß√£o

A arquitetura √© modular e extens√≠vel, permitindo personaliza√ß√£o de modelos LLM, perfis de processamento e templates de prompt. Veja exemplos e instru√ß√µes nos diret√≥rios `src/configs/llms`, `src/configs/profile` e `src/configs/templates`.

## üìñ Uso

Sintaxe:
```bash
python main.py <pdf_path> [op√ß√µes]
```

Principais op√ß√µes:
- `--profile` Perfil de configura√ß√£o (ex: openvas, tenable)
- `--LLM` Modelo LLM a usar (ex: gpt4, llama3)
- `--convert` Formato de sa√≠da (`csv`, `xlsx`, `tsv`, `all`)
- `--output` Caminho do arquivo convertido
- `--output-dir` Diret√≥rio para arquivos convertidos
- `--csv-delimiter` Delimitador CSV
- `--csv-encoding` Codifica√ß√£o CSV

Exemplos:
```bash
python main.py relatorio.pdf --profile openvas --convert csv
python main.py relatorio.pdf --LLM deepseek --convert all --output-dir ./resultados
```

## üìÑ Formato de sa√≠da

Gera JSON estruturado com campos como `Name`, `description`, `cvss`, `severity`, `solution`, `port`, `protocol`, `references`, al√©m de campos espec√≠ficos para cada scanner. Permite convers√£o para CSV/XLSX/TSV.

## üîß Resolu√ß√£o de problemas

- Erro de modelo: atualize o modelo nas configura√ß√µes
- Arquivo n√£o encontrado: verifique o caminho do PDF
- API key inv√°lida: revise a chave nas configura√ß√µes
- Limite de quota: aguarde ou troque de provedor

## üìÅ Estrutura do projeto

```
pdf-vulnerability-extractor/
‚îú‚îÄ‚îÄ main.py              # Script principal
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias
‚îú‚îÄ‚îÄ README.md            # Este arquivo
‚îú‚îÄ‚îÄ src/                 # C√≥digo fonte modular
‚îÇ   ‚îú‚îÄ‚îÄ configs/         # Configura√ß√µes (LLMs, perfis, templates)
‚îÇ   ‚îú‚îÄ‚îÄ converters/      # Conversores de sa√≠da
‚îÇ   ‚îî‚îÄ‚îÄ utils/           # Utilit√°rios de processamento
‚îî‚îÄ‚îÄ data/                # Dados de entrada e sa√≠da
```

## Objetivo

O objetivo geral deste trabalho √© desenvolver um m√©todo automatizado, baseado em Processamento de Linguagem Natural (PLN) e Large Language Models (LLMs), para construir datasets de vulnerabilidades. Especificamente, prop√µe-se extrair e estruturar informa√ß√µes a partir de relat√≥rios heterog√™neos dos scanners OpenVAS e Tenable WAS, convertendo seus dados n√£o estruturados em um formato padronizado que facilite a gest√£o de riscos. Com isso, busca-se assegurar consist√™ncia entre diferentes ferramentas e reduzir substancialmente o esfor√ßo manual. O uso de GPT-4.1 demonstrou-se vi√°vel para gerar datasets utiliz√°veis em modelos de aprendizado de m√°quina. Al√©m disso, o m√©todo contempla futura integra√ß√£o de m√≥dulos de anonimiza√ß√£o, automa√ß√£o de rotulagem e atualiza√ß√£o cont√≠nua, visando tornar os datasets seguros, reutiliz√°veis e representativos.

## Metodologia

O m√©todo automatiza a extra√ß√£o de vulnerabilidades a partir de relat√≥rios em formato PDF gerados pelos scanners OpenVAS e Tenable WAS. O pipeline √© organizado em fases modulares para assegurar a integridade e a consist√™ncia dos dados, lidando com a heterogeneidade estrutural e sem√¢ntica entre as ferramentas:

1. **Extra√ß√£o Textual e Divis√£o (Chunking):**  
   O processo inicia com a leitura do relat√≥rio e a extra√ß√£o do conte√∫do textual, preservando a fidelidade aos dados originais. O texto √© dividido em blocos l√≥gicos (chunks) para manter o contexto de cada vulnerabilidade dentro das limita√ß√µes de tokens dos modelos de linguagem, sendo utilizados blocos m√©dios de aproximadamente 9.000 caracteres nos experimentos.

2. **Processamento com Mapeamento Expl√≠cito:**  
   Cada bloco √© processado por um prompt espec√≠fico que orienta o LLM (como GPT-4.1) a identificar os campos relevantes (descri√ß√£o, impacto, solu√ß√£o, refer√™ncias). Para garantir a padroniza√ß√£o, foi implementado um mapeamento expl√≠cito no prompt que associa os campos espec√≠ficos de cada scanner (como Vulnerability Insight do OpenVAS e Risk Information do Tenable WAS) a um conjunto de r√≥tulos generalizados. Campos inexistentes s√£o preenchidos com `NULL` para evitar a gera√ß√£o de informa√ß√µes artificiais.

3. **P√≥s-processamento e Consolida√ß√£o:**  
   Os dados extra√≠dos s√£o validados e consolidados. Esta fase inclui a remo√ß√£o de duplica√ß√µes, verifica√ß√£o da conformidade sint√°tica e a reconstru√ß√£o do conjunto completo de vulnerabilidades. Essa etapa permite a an√°lise e contagem final das vulnerabilidades extra√≠das a partir de diferentes arquivos e fontes de relat√≥rios (OpenVAS e Tenable WAS), resultando em um dataset unificado.

## Arquitetura Proposta

- Leitura e extra√ß√£o de texto de PDFs (OpenVAS/Tenable)
- Divis√£o em chunks para processamento eficiente por LLMs
- Prompting e mapeamento de campos para padroniza√ß√£o dos dados
- Conversores para formatos CSV/XLSX
- Valida√ß√£o, deduplica√ß√£o e consolida√ß√£o dos dados extra√≠dos

## Tecnologias Utilizadas

- Python 3.x
- GPT-4.1 (OpenAI API)
- PyPDF2, pdfplumber (extra√ß√£o de texto)
- Pandas (manipula√ß√£o de dados)
- Ferramentas de automa√ß√£o e scripts customizados
- OpenVAS e Tenable WAS (fontes dos relat√≥rios)

## Resultados Obtidos

O pipeline proposto foi executado sobre um conjunto de 478 vulnerabilidades originadas de aplica√ß√µes vulner√°veis propositalmente (DVWA, GRAV e OWASP Juice Shop), al√©m de inst√¢ncias rodando localmente, incluindo servidores web, bancos de dados, servi√ßos de rede e esta√ß√µes de trabalho, para garantir diversidade de contexto. A extra√ß√£o estruturada com GPT‚Äë4.1, seguida pelos processos de normaliza√ß√£o de severidade e deduplica√ß√£o sem√¢ntica, resultou nos dados consolidados utilizados nesta an√°lise.

### Distribui√ß√£o por Severidade Normalizada

![Distribui√ß√£o das vulnerabilidades por n√≠vel de severidade padronizado](figuras/barras_severidade_padronizada.png)
*Figura: Distribui√ß√£o das vulnerabilidades por n√≠vel de severidade padronizado (n = 478)*

- **High**: 136 (28,5%)
- **Medium**: 203 (42,5%)
- **Low**: 25 (5,2%)
- **Log**: 114 (23,8%)

As severidades Medium e High representam conjuntamente 71% dos achados, evidenciando exposi√ß√£o significativa a riscos cr√≠ticos e de alta probabilidade de explora√ß√£o.

### An√°lise de Recorr√™ncia e Duplicidade

![Vulnerabilidades mais recorrentes por nome original](figuras/duplicatas_por_nome2.png)
*Figura: Vulnerabilidades mais recorrentes por nome original (top 30 de 312 entradas √∫nicas)*

As vulnerabilidades mais frequentes segundo o campo `Name` original do OpenVAS apresentaram alta concentra√ß√£o em problemas de configura√ß√£o e obsolesc√™ncia de protocolos SSL/TLS (certificados expirados, su√≠tes criptogr√°ficas fracas, falta de PFS, suporte a SSLv3), exposi√ß√£o repetida de servi√ßos legados em claro (FTP, Telnet, VNC, rexec/rlogin/rsh), m√∫ltiplas inst√¢ncias de d√≠vida t√©cnica em componentes espec√≠ficos (phpMyAdmin, TWiki, PostgreSQL, Samba e vers√µes obsoletas do PHP), al√©m de achados consolidados de invent√°rio (Services, OS Detection) com elevada cardinalidade.

Ap√≥s a desduplica√ß√£o sem√¢ntica realizada com combina√ß√£o de correspond√™ncia exata de CVE/CPE, o conjunto original foi reduzido de 478 para 294 entradas √∫nicas, uma diminui√ß√£o de 38,5%. A abordagem eliminou redund√¢ncias por host, mantendo, entretanto, a representatividade global do risco.

##  Licen√ßa

Este projeto √© fornecido como est√°, para fins educacionais e de pesquisa.
